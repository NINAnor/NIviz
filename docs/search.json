[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"","code":""},{"path":"downloading-and-preparing-example-data.html","id":"downloading-and-preparing-example-data","chapter":"2 Downloading and preparing example data","heading":"2 Downloading and preparing example data","text":"Fill username (NINA email) password.Choose indicator(s) want, use NIcalc “importDatasetApi” function retrieve data database save dataset locally.Next, need assemble data set. shouldn’t necessary since data already present. One thing notices jerv, distribution familiy parameters appear assembling.Save filesLoading datafiles back R.reference values also bootstrapped uncertainties. coded year = NA. might, however, just end using row means.Save files","code":"\nif(!require(NIcalc)){\n  devtools::install_github(\"NINAnor/NIcalc\", build_vignettes = F)\n}\nlibrary(NIcalc)\n\nmyUser <- \"user@nina.no\" # insert NINA email\nmyPwd  <- \"\" # secret password\nindicator <- c(\"Dikesoldogg\",\n               \"Jerv\",\n               \"Elg\",\n               \"Lomvi\",\n               \"Havørn\",\n               \"Lange\")\nfor(i in indicator){\nindicatorImport <- NULL\nindicatorImport <- NIcalc::importDatasetApi(\n  username = myUser,\n  password = myPwd,\n  indic = i,\n  year = c(\"1990\",\"2000\",\"2010\",\"2014\",\"2019\"))\n\nassign(paste0(i, \"_import\"), indicatorImport)\n}\npath <- \"P:/41201612_naturindeks_2021_2023_database_og_innsynslosning/temp/\"\n\nfor(i in indicator){\n  temp <- get(paste0(i, \"_import\"))\n  saveRDS(temp, paste0(path, i, \"_import.rds\"))\n}\n\nfor(i in indicator){\n  temp <- paste0(path, i, \"_import.rds\")\n  assign(i, readRDS(temp))\n}\n# Spesify all of Norway incl the five regions, som NIunits:\nmyNIunits <- c(allArea = T, parts = T, counties = F)\n# Include all BSunits (kommuner) irrespective of the proportion of the main ecosystems:\nmyPartOfTotal <- 0\n\nfor(i in indicator){\n\n  temp <- get(paste0(i, \"_import\"))\n  assemeble <- NULL\n  assemeble <- NIcalc::assembleNiObject(\n    inputData = temp,\n    predefNIunits = myNIunits, \n    partOfTotal = myPartOfTotal, \n    indexType = \"thematic\",\n    part = \"ecosystem\",\n    total = \"total\")  \n  \n  # I dont se the output changing if I for example chose total = marine. Perhaps 'part' and 'total' only becomes an issue if partOfTotal != 0.\n  \n  assign(paste0(i, \"_assemble\"), assemeble)\n\n}\n\nfor(i in indicator){\n  temp <- get(paste0(i, \"_assemble\"))\n  saveRDS(temp, paste0(\"data/\", i, \"_assemebled.rds\"))\n}\nfor(i in indicator){\n  temp <- paste0(\"data/\", i, \"_assemebled.rds\")\n  assign(i, readRDS(temp))\n}\nmyYears <- as.character(c(1990,2000,2010,2014,2019))\n\n\nfor(j in indicator){\nprint(j)\n\n  temp <- get(j)\n  temp2 <- get(paste0(j, \"_import\"))\n  temp_comb <- data.frame(NULL)\n  myMat2 <- NULL\n  myMat2_comb <- NULL\n  obstype <- NULL\n  \n  \n  obstype <- temp$referenceValues$distributionFamilyName\n  obstype[!is.na(obstype)] <- \"tradObs\"\n  obstype[is.na(obstype)]  <- \"customObs\"\n  \nmyMatr <- NIcalc::sampleObsMat(\n  ICunitId           = temp$referenceValues$ICunitId, \n  value              = temp$referenceValues$expectedValue,\n  distrib            = temp$referenceValues$distributionFamilyName,\n  mu                 = temp$referenceValues$distParameter1,\n  sig                = temp$referenceValues$distParameter2,\n  customDistribution = temp$referenceValues$customDistribution,\n  obsType            = obstype,\n  nsim =1000\n        )  \n  \nmyMatr <- as.data.frame(myMatr)\nmyMatr <- myMatr %>%\n  tibble::add_column(.before=1,\n    ICunitID = row.names(myMatr))\n\nmyMatr <- myMatr %>%\n  tibble::add_column(.after = 1,\n      year = NA) \n  \nfor(i in 1:length(myYears)){\nprint(i)\n\nobs <- NULL\n  obs <- temp$indicatorValues[[i]]$distributionFamilyName\n  obs[!is.na(obs)] <- \"tradObs\"\n  obs[is.na(obs)]  <- \"customObs\"\n\n\nmyMat <- NIcalc::sampleObsMat(\n  ICunitId           = temp$indicatorValues[[i]]$ICunitId, \n  value              = temp$indicatorValues[[i]]$expectedValue,\n  distrib            = temp$indicatorValues[[i]]$distributionFamilyName,\n  mu                 = temp$indicatorValues[[i]]$distParameter1,\n  sig                = temp$indicatorValues[[i]]$distParameter2,\n  customDistribution = temp$indicatorValues[[i]]$customDistribution,\n  obsType            = obs,\n  nsim               = 1000\n          \n)\n\n\nmyMat2 <- as.data.frame(myMat)\n\nmyMat2 <- myMat2 %>%\n  tibble::add_column(.before=1,\n    ICunitID = row.names(myMat))\n\nmyMat2 <- myMat2 %>%\n  tibble::add_column(.after = 1,\n    year = myYears[i]) \n\nmyMat2_comb <- rbind(myMat2_comb, myMat2)\n\n }\n\ncomb <- rbind(myMatr, myMat2_comb)\n\ncomb <- comb %>%\n  tibble::add_column(.after = 1,\n    ICunitName = temp2$ICunits$name[match(\n      comb$ICunitID, temp2$ICunits$id)])\n\ncomb2 <- comb[!is.na(comb$year),]\ncomb3 <- comb[is.na(comb$year),]\ncomb3$ref_mean <- rowMeans(comb3[,-c(1:3)])\n\ncombScaled <- comb2 %>%\n  tidyr::pivot_longer(cols = starts_with(\"V\")) \n\ncombScaled <- combScaled %>%\n  tibble::add_column(ref = comb3$ref_mean[\n    match(combScaled$ICunitID, comb3$ICunitID)])\ncombScaled$scaledIndicator <- combScaled$value/combScaled$ref\ncombScaled <- dplyr::select(combScaled,\n                     -name,\n                     -value,\n                     -ref)\n\nassign(paste0(j, \"_bootstrapped_raw\"), comb)\nassign(paste0(j, \"_bootstrapped_scaled\"), combScaled)\n\n}\n\nfor(i in indicator){\n  temp <- get(paste0(i, \"_bootstrapped_raw\"))\n    temp <- get(paste0(i, \"_bootstrapped_scaled\"))\n\n  saveRDS(temp, paste0(\"data/\", i, \"_bootstrapped_raw.rds\"))\n    saveRDS(temp, paste0(\"data/\", i, \"_bootstrapped_scaled.rds\"))\n\n}"},{"path":"cross.html","id":"cross","chapter":"3 Time series","heading":"3 Time series","text":"","code":""},{"path":"cross.html","id":"raw-data","chapter":"3 Time series","heading":"3.1 Raw data","text":"","code":"\nlibrary(plotly)\n## TODO change to correct data source\npasserinesImport <- readRDS(\"data/passerinesImport.rds\")\n\ndat=passerinesImport$indicatorObservations$indicatorValues \n\ndat$yearName=as.numeric(dat$yearName) # convert character vector to numeric years\nsum_dat=dat %>% \n  group_by(ICunitName, yearName) %>% \n  summarise(mnExpected=mean(expectedValue, na.rm=TRUE),\n            mnUpper=mean(upperQuantile, na.rm=TRUE),\n            mnLower=mean(lowerQuantile, na.rm=TRUE)) # summerise the data to mean values\n\np=sum_dat %>% \n  ggplot(aes(as.numeric(yearName), mnExpected, col=ICunitName))+\n  geom_line()+\n  geom_pointrange(aes(x=as.numeric(yearName), y=mnExpected, ymin=mnLower, ymax=mnUpper))+\n  geom_point(data=dat, aes(as.numeric(yearName), expectedValue, alpha=0.2))+\n  labs(x=\"year\", y=\"Expected value\")+\n  theme_NIseries()\np2=ggplotly(p)\np2 %>% layout(\n  updatemenus = list(\n    list(\n      type = \"list\",\n      label = 'Category',\n      buttons = list(\n        list(method = \"restyle\",\n             args = list('visible', c(TRUE, FALSE, FALSE)),\n             label = \"Nord-Norge\"),\n        list(method = \"restyle\",\n             args = list('visible', c(FALSE, TRUE, FALSE)),\n             label = \"Norge\"),\n        list(method = \"restyle\",\n             args = list('visible', c(FALSE, FALSE, TRUE)),\n             label = \"Sør-Norge\")\n      )\n    )\n  )\n) # Add drop down menus for the data"},{"path":"cross.html","id":"scaled-data","chapter":"3 Time series","heading":"3.2 Scaled data","text":"","code":"\nElg_assemebled<- readRDS(\"data/Elg_assemebled.rds\")\nmycols=c(\"ICunitName\" ,\"yearName\", \"expectedValue\",\"lowerQuantile\", \"upperQuantile\")\n\ndata_list<-lapply(Elg_assemebled$indicatorValues, function(x) x%>% select(mycols))\n\ndat<-bind_rows(data_list, .id = \"column_label\")\n\n# plot\nsum_dat=dat %>% \n  group_by(ICunitName, yearName) %>% \n  summarise(mnExpected=mean(expectedValue, na.rm=TRUE),\n            mnUpper=mean(upperQuantile, na.rm=TRUE),\n            mnLower=mean(lowerQuantile, na.rm=TRUE)) # summerise the data to mean values\nsource(\"R/ggplotTheme.R\")\np=sum_dat %>% \n  ggplot(aes(as.numeric(yearName), mnExpected, col=ICunitName))+\n  geom_line()+\n  geom_pointrange(aes(x=as.numeric(yearName), y=mnExpected, ymin=mnLower, ymax=mnUpper))+\n  geom_point(data=dat, aes(as.numeric(yearName), expectedValue, alpha=0.2))+\n  labs(x=\"year\", y=\"Expected value\")+\n  theme_NIseries()\np2=ggplotly(p)\np2 %>% layout(\n  updatemenus = list(\n    list(\n      type = \"list\",\n      label = 'Category',\n      buttons = list(\n        list(method = \"restyle\",\n             args = list('visible', c(TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[2]),\n        list(method = \"restyle\",\n             args = list('visible', c(FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[8]),\n        list(method = \"restyle\",\n             args = list('visible', c(FALSE, FALSE,TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[5]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[18]),\n        list(method = \"restyle\",\n             args = list('visible', c(FALSE, FALSE, FALSE,FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[3]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[11]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[13]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[15]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[16]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[4]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[10]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[12]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[14]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[7]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[17]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE)),\n             label = unique(dat$ICunitName)[9]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE)),\n             label = unique(dat$ICunitName)[6]),\n        list(method = \"restyle\",\n             args = list('visible', c( FALSE, FALSE, FALSE,FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE)),\n             label = unique(dat$ICunitName)[1])\n      )\n    )\n  )\n) # Add drop down menus for the data"},{"path":"maps.html","id":"maps","chapter":"4 Maps","heading":"4 Maps","text":"","code":""},{"path":"maps.html","id":"raw-data-1","chapter":"4 Maps","heading":"4.1 Raw data","text":"","code":""},{"path":"maps.html","id":"scaled-data-1","chapter":"4 Maps","heading":"4.2 Scaled data","text":"","code":""},{"path":"maps.html","id":"jerv","chapter":"4 Maps","heading":"4.2.1 Jerv","text":"","code":""},{"path":"maps.html","id":"prepare-ni-data","chapter":"4 Maps","heading":"4.2.1.1 Prepare NI data","text":"jerv (wolverine) data downloaded using R/singleIndicator.R script importDatasetApi() function,, subsequently assembleNiObject() function, now can simply import .data file contains raw data form expected values BSunits (municipalities). actually want keep original geometeris eight rovviltregioner, need focus ICunits instead.\nFigure 4.1: Estimated number \nwolverine 2019, exported NI database.\ndata also contains upper lower quantiles, can also get full probability distribution sample get standard deviations, also probability functions can sample :\nFigure 4.2: Probability distribuition number wolverine, resamlped using data NI database R function NIcalc-package.\nreason extected values far mean distributions. exercise , get problem . think difference use eco = NULL time, importDatasetApi(), cause output somehow split forest alpine ecosystems. ignore example.can also get reference values way, divide one get scaled values\nFigure 4.3: Example distribution scaled indicator values wolverine.\ncreate data frame mean indicator values SD.\nFigure 4.4: Table showing different parameters summary statistics wolverine indicator.\nspecial case maybe, sd often larger mean.Btw, use inbuilt NIcalc functions get indicator value, like , aggregate regions, want keep original geometry.\nFigure 4.5: scaled indicator values wolverine across Norway.\n","code":"\njerv <- readRDS(\"data/Jerv_assemebled.rds\")\npar(mar=c(9,5,1,1))\nbarplot(jerv$indicatorValues$`2019`$expectedValue,\n        names.arg = jerv$indicatorValues$`2019`$ICunitName, \n        las=2,\n        ylab = \"Estimated number of\\nwolverine in 2019\")\n# bruker tradOb siden custumDist er NA. Dette er ikke en generisk løsning. \nobstype <- rep(\"tradObs\", nrow(jerv$indicatorValues$'2019'))\n\n#myYears <- as.character(c(1990,2000,2010,2014,2019))\nmyYears <- as.character(c(2019))\n\nfor(i in 1:length(myYears)){\n# print(i)\n\nmyMat <- NIcalc::sampleObsMat(\n  ICunitId           = jerv$indicatorValues[[i]]$ICunitId, \n  value              = jerv$indicatorValues[[i]]$expectedValue,\n  distrib            = jerv$indicatorValues[[i]]$distributionFamilyName,\n  mu                 = jerv$indicatorValues[[i]]$distParameter1,\n  sig                = jerv$indicatorValues[[i]]$distParameter2,\n  customDistribution = jerv$indicatorValues[[i]]$customDistribution,\n          obsType = obstype,\n          nsim = 1000\n          \n)\nassign(paste0(\"myMat\", myYears[i]), myMat)\n}\n\npar(mfrow = c(1,2))\nhist(myMat2019[1,], main = \"Rovviltregion 1\", xlab = \"\")\nhist(myMat2019[8,], main = \"Rovviltregion 8\", xlab = \"\")\nmyMatr <- NIcalc::sampleObsMat(\n            jerv$referenceValues$ICunitId, \n            jerv$referenceValues$expectedValue,\n            jerv$referenceValues$distributionFamilyName,\n            mu = jerv$referenceValues$distParameter1,\n            sig = jerv$referenceValues$distParameter2,\n            customDistribution = jerv$referenceValues$customDistribution,\n            obsType = obstype,\n            nsim =1000\n        )\n\ntemp <- colSums(myMat2019)/colSums(myMatr)\nhist(temp, xlab = \"Scaled indicator value for wolverine\",main=\"\")\nlibrary(matrixStats)\n#> Warning: package 'matrixStats' was built under R version\n#> 4.1.3\n#> \n#> Attaching package: 'matrixStats'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     count\njerv_tbl <- data.frame(\"raw2019\" = round(rowMeans(myMat2019), 2),\n                       \"sd2019\"  = round(matrixStats::rowSds(myMat2019), 2),\n                       \"ref\"     = round(rowMeans(myMatr), 2))\njerv_tbl$scaled <- round(jerv_tbl$raw2019/jerv_tbl$ref, 2)\njerv_tbl$cv <- round(jerv_tbl$sd2019/jerv_tbl$raw2019, 2)\njerv_tbl$region <- jerv$indicatorValues$`2019`$ICunitName\nDT::datatable(jerv_tbl)\njervComp <- NIcalc::calculateIndex(\n  x       = jerv,\n  nsim     = 1000,\n  awBSunit = \"terrestrialArea\",\n  fids     = F,    # should fidelities be ignored in \n                   # the calculation of Wi?\n  tgroups  = F, # should grouping of indicators \n                   # into trophic and key indicator \n                   # groups be ignored\n  keys     = \"specialWeight\", #\"ignore\",\n)\n#> Indices for NIunits 'wholeArea', 'E', 'S', 'W', 'C', 'N'\n#> and years '1990', '2000', '2010', '2014', '2019' will be calculated.\n#> The 30 index distributions will each be based on  1000 simulations.\n#> There are 8 ICunits with observations in data set 'jerv'.\n#> \n#> Calculating weights that are the same for all years .....\n#> \n#> Sampling reference values .....\n#> \n#> Sampling and scaling indicator observations from  1990 .....\n#> \n#> Sampling and scaling indicator observations from  2000 .....\n#> \n#> Sampling and scaling indicator observations from  2010 .....\n#> \n#> Sampling and scaling indicator observations from  2014 .....\n#> \n#> Sampling and scaling indicator observations from  2019 .....\nplot(jervComp$wholeArea)"},{"path":"maps.html","id":"get-geometries","chapter":"4 Maps","heading":"4.2.1.2 Get geometries","text":"can get spatial geometries associated data. called rovviltregioner. eight . actually linked BS-units (municipalities), don’t want plot outlines municipalities.\ngeometries appropriate spatial units indicator can downloaded .json format via previously created API nature index database: https://ninweb08.nina./NaturindeksAPI/index.html\nget file specific indicator, one needs enter numerical indicator id “/api/Indicator/{id}/Areas” click download. converted .json file shapefiles use R.Clip outline Norway make look pretty","code":"\npath <- \"P:/41201612_naturindeks_2021_2023_database_og_innsynslosning/Pilot_Forbedring_Innsynsløsning/Shapefiles/Jerv\"\nlibrary(sf)\n#> Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\nrov <- sf::read_sf(path)\nrov <- sf::st_make_valid(rov)\nrov <- rov[rov$area!=\"DEF jerv\",]\npath <- \"data/outlineOfNorway_EPSG25833.shp\"\nnor <- sf::read_sf(path)\nnor <- st_transform(nor, crs=st_crs(rov))\nrov <- st_intersection(rov, nor)\n#> Warning: attribute variables are assumed to be spatially\n#> constant throughout all geometries"},{"path":"maps.html","id":"link-data-and-geometries","chapter":"4 Maps","heading":"4.2.1.3 Link data and geometries","text":"copy data table geo-file.can attempt create nice example maps indicator uncertainty shown parallel scaled values.","code":"\nrov$scaledIndicator <- jerv_tbl$scaled[match(rov$area, jerv_tbl$region)]\nrov$cv <- jerv_tbl$cv[match(rov$area, jerv_tbl$region)]\nrov$raw <- jerv_tbl$raw2019[match(rov$area, jerv_tbl$region)]\n# colour palette with 10 colours\npal <- grDevices::colorRampPalette(NIviz_colours[[\"IndMap_cols\"]])(10)\n\none <- tm_shape(rov)+\n  tm_polygons(col=\"scaledIndicator\", \n              border.col = \"white\",\n              style = \"cont\",\n              breaks = seq(0,1, length.out = 11),\n              palette = pal)\n\n\ntwo <- tm_shape(rov)+\n  tm_polygons(col=\"cv\", \n              border.col = \"black\")\n\n#three <- tm_shape(rov)+\n#  tm_polygons(col=\"raw\", \n#              border.col = \"white\")\n\n\ntmap_mode(\"view\")\n#> tmap mode set to interactive viewing\n\ntmap_arrange(one, two, \n             sync=T,\n             widths = c(.75, .25),\n             heights = c(1, 0.5)\n             )"},{"path":"other-figures.html","id":"other-figures","chapter":"5 Other figures","heading":"5 Other figures","text":"","code":""},{"path":"other-figures.html","id":"gradient-density-plots-for-interactive-maps","chapter":"5 Other figures","heading":"5.1 Gradient density plots for interactive maps","text":"maps presented webpage include representation uncertainty. One way including information without add additional (layers ) maps build interactive functions included far present probability distribution given region year. displayed box currently appears hovering area displays area name average indicator value.make density plots, use previously simulated bootstrap samples, using Jerv example:considered forcing indicator values > 1 display 1, messes plotting density functions. Still, conversion required calculating point estimate (median) therefore make copy data values larger 1.Next, need manually calculate probability densities indicator values year area. necessary making density plots color gradient fill (see alternative using “ggridges” package require intermediate step).can proceed plotting probability density functions color gradient line:Gradient density plots might also useful types visualization indicator index data. example, attractive way using ridgeplots visualizing time series inclusing uncertainty. look something like :","code":"\n\ni <- \"Jerv\"\nbootStrp <- readRDS(paste0(\"data/\", i, \"_bootstrapped_scaled.rds\"))\nhead(bootStrp)\n#> # A tibble: 6 x 4\n#>   ICunitID ICunitName      year  scaledIndicator\n#>   <chr>    <chr>           <chr>           <dbl>\n#> 1 1302     Rovviltregion 8 1990            0.194\n#> 2 1302     Rovviltregion 8 1990            0.233\n#> 3 1302     Rovviltregion 8 1990            0.190\n#> 4 1302     Rovviltregion 8 1990            0.207\n#> 5 1302     Rovviltregion 8 1990            0.199\n#> 6 1302     Rovviltregion 8 1990            0.164\nbootStrp1 <- bootStrp\nbootStrp1$scaledIndicator[which(bootStrp1$scaledIndicator > 1)] <- 1\nyears <- unique(bootStrp$year)\nareas <- unique(bootStrp$ICunitName)\n\npDens <- data.frame()\nfor(t in years){\n  for(a in areas){\n    \n    bootStrp_sub <- subset(bootStrp, year == t & ICunitName == a)\n    \n    pDens_a_t <- data.frame(\n      ICunitName = a,\n      year = t, \n      x = density(bootStrp_sub$scaledIndicator)$x,\n      y = density(bootStrp_sub$scaledIndicator)$y\n    )\n    \n    pDens <- rbind(pDens, pDens_a_t)\n  }\n}\n\n# Set maximum value (we will not plot beyond 4)\n\nfor(t in years){\n\n  # Take data subsets for a given year\n  bootStrp_yr <- bootStrp[which(bootStrp$year == t),]\n  bootStrp1_yr <- bootStrp1[which(bootStrp1$year == t),]\n  pDens_yr <- pDens[which(pDens$year == t),]\n\n  # Extract distribution medians\n  sum_values <- bootStrp1_yr %>% \n    group_by(ICunitName) %>%\n    summarise(sumStat = median(scaledIndicator)) \n  \n  # Set maximum plotting value (never > 5) and mapping for custom color scale\n  maxVal <- ifelse(max(pDens_yr$x) > 5, 5, max(pDens_yr$x))\n  \n  if(maxVal < 1+1/9){\n    valuesMap <- c(-0.1, seq(0, 1, length.out = 10))\n    colorMap <- c(\"#1F8C81\", NIviz_colours$IndMap_cols)\n  }else{\n    valuesMap <- c(-0.1, c(seq(0, 1, length.out = 10), maxVal)/maxVal)\n    colorMap <- c(\"#1F8C81\", NIviz_colours$IndMap_cols, \"#4B4BAF\")\n  }\n  \n  # Plot densities\n  print(\n    ggplot(subset(pDens_yr, x <= maxVal), aes(x, y)) + \n      geom_segment(aes(xend = x, yend = 0, colour = x)) + \n      #scale_color_NIviz_c(name = \"IndMap_cols\") + \n      scale_colour_gradientn(colours = colorMap,\n                             values = valuesMap,\n                             limits = c(-0.01, ifelse(maxVal < 1, 1, maxVal))) +\n      ggtitle(paste0(i, \" (\", t, \")\")) +\n      xlab(\"Value\") + \n      geom_vline(data = sum_values, aes(xintercept = sumStat)) + \n      facet_wrap(~ ICunitName, scales = 'free') + \n      theme_classic() + \n      theme(strip.background = element_blank(), \n            legend.title = element_blank(),\n            axis.line.y = element_blank(), axis.ticks.y = element_blank(),\n            axis.text.y = element_blank(), axis.title.y = element_blank())\n  )\n}\n\nfor(a in areas){\n  \n  # Take data subsets for a given area\n  bootStrp_ar <- bootStrp[which(bootStrp$ICunitName == a),]\n  pDens_ar <- pDens[which(pDens$ICunitName == a),]\n  \n  # Set maximum plotting value (never > 5) and mapping for custom color scale\n  maxVal <- ifelse(max(pDens_ar$x) > 5, 5, max(pDens_ar$x))\n  \n  if(maxVal < 1+1/9){\n    valuesMap <- c(-0.1, seq(0, 1, length.out = 10))\n    colorMap <- c(\"#1F8C81\", NIviz_colours$IndMap_cols)\n  }else{\n    valuesMap <- c(-0.1, c(seq(0, 1, length.out = 10), maxVal)/maxVal)\n    colorMap <- c(\"#1F8C81\", NIviz_colours$IndMap_cols, \"#4B4BAF\")\n  }\n  \n  # Plot densities\n  print(\n  \n  ggplot(subset(bootStrp_ar, scaledIndicator <= maxVal), aes(x = scaledIndicator, y = year, fill = stat(x))) +\n    geom_density_ridges_gradient(scale = 5, rel_min_height = 0.01, quantile_lines = TRUE, quantiles = 2) + \n    scale_fill_gradientn(colours = colorMap,\n                         values = valuesMap,\n                         limits = c(-0.02, ifelse(maxVal < 1, 1, maxVal))) +\n    ggtitle(paste0(i, \" (\", a, \")\")) + \n    xlab(\"Scaled indicator value\") + ylab(\"\") + \n    theme_classic() + \n    theme(legend.title = element_blank(), plot.title = element_text(hjust = 0.5),\n          axis.line.y = element_blank(), axis.ticks.y = element_blank(),\n          panel.grid.major.y = element_line(color = \"grey80\"))\n  )\n  \n}\n#> Picking joint bandwidth of 0.00457#> Picking joint bandwidth of 0.00947#> Picking joint bandwidth of 0.00715#> Picking joint bandwidth of 0.00184#> Picking joint bandwidth of 0.00215#> Picking joint bandwidth of 0.0101#> Picking joint bandwidth of 0.00966#> Picking joint bandwidth of 0.0112"},{"path":"other-figures.html","id":"ecosystem-fidelity","chapter":"5 Other figures","heading":"5.2 Ecosystem fidelity","text":"indicators assigned least one ecosystem, fair number assigned multiple ecosystems means proportions. Wolverine (Jerv), example, assigned 25% forest 75% mountain. basic information easily displayed indicator’s page naturindeks..relevant information found assembled indicator data $indicators:ecosystem type relevant specific indicator appears separate column dataframe, contains value representing % fidelity ecosystem type.Using separately stored information available ecosystem types, can assemble data example indicators:gives us dataframe indicators fidelity different ecosystems:plotting, match integer ecosystem IDs make sure colour mapping works correctly:Next, ’ll visualize information indicator means pie charts.\nDepending large pie charts appear website end, may necessary move percentage labels outside pies. bit cumbersome, works code unless indicator belongs 100 % one dataset. case, solution print percentage label (see indicator Lange) figured fix yet.","code":"\n\ni <- \"jerv\"\nindexData <- readRDS(paste0(\"data/\", i, \"_assemebled.rds\"))\n\nstr(indexData$indicators)\n#> 'data.frame':    1 obs. of  9 variables:\n#>  $ id               : num 88\n#>  $ name             : chr \"Jerv\"\n#>  $ keyElement       : logi FALSE\n#>  $ functionalGroup  : chr \"Topp-predator generalist\"\n#>  $ functionalGroupId: num 8\n#>  $ scalingModel     : chr \"Low\"\n#>  $ scalingModelId   : num 1\n#>  $ Fjell            : num 75\n#>  $ Skog             : num 25\n# Load ecosystem info\nEcoSysInfo <- readRDS(\"data/EcosystemInfo.rds\")\n\n# Indicator list\nindicator <- c(\"Dikesoldogg\",\n               \"Jerv\",\n               \"Elg\",\n               \"Lomvi\",\n               \"Havørn\",\n               \"Lange\")\n\n# Assemble fidelity data\nfidData <- data.frame()\n\nfor(i in 1:length(indicator)){\n  \n  indexData <- readRDS(paste0(\"data/\", indicator[i], \"_assemebled.rds\"))\n  \n  ColIdx <- which(names(indexData$indicators) %in% EcoSysInfo$ecosystem)\n\n  fidDataI <- data.frame(\n    indicator = indicator[i],\n    ecosystem = names(indexData$indicators)[ColIdx],\n    fidelity = unname(as.numeric(indexData$indicators[,ColIdx])))\n  \n  fidData <- rbind(fidData, fidDataI)\n}\nprint(fidData)\n#>     indicator         ecosystem fidelity\n#> 1 Dikesoldogg           Våtmark      100\n#> 2        Jerv             Fjell       75\n#> 3        Jerv              Skog       25\n#> 4         Elg              Skog      100\n#> 5       Lomvi      Hav-pelagisk       67\n#> 6       Lomvi Kystvann-pelagisk       33\n#> 7      Havørn Kystvann-pelagisk      100\n#> 8       Lange           Havbunn       80\n#> 9       Lange     Kystvann-bunn       20\nfidData <- merge(fidData, EcoSysInfo, all.x = TRUE)\nEcoSys_cols <- NIviz_colours$EcoSys_cols[1:11]\nnames(EcoSys_cols) <- EcoSysInfo$ecosystem\n\nfor(i in 1:length(indicator)){\n  \n  sub_fidData <- fidData[which(fidData$indicator == indicator[i]),]\n  \n  print(\n    ggplot(sub_fidData, aes(x = \"\", y = fidelity, fill = fct_inorder(ecosystem))) +\n    ggtitle(indicator[i]) + \n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = paste0(fidelity, \"%\")),\n              position = position_stack(vjust = 0.5)) +\n    coord_polar(theta = \"y\") +\n    scale_fill_manual(name = \"Økosystem\", values = EcoSys_cols[which(names(EcoSys_cols) %in% sub_fidData$ecosystem)]) + \n    theme_void()\n  )\n\n}\nfor(i in 1:length(indicator)){\n  \n  sub_fidData <- fidData[which(fidData$indicator == indicator[i]),]\n  \n  posData <- sub_fidData %>% \n  mutate(csum = rev(cumsum(rev(fidelity))), \n         pos = fidelity/2 + lead(csum, 1),\n         pos = if_else(is.na(pos), fidelity/2, pos))\n  \n  print(\n  ggplot(sub_fidData, aes(x = \"\", y = fidelity, fill = ecosystem)) +\n    ggtitle(indicator[i]) + \n    geom_bar(stat = \"identity\") +\n    coord_polar(theta = \"y\") +\n    #scale_fill_manual(values = EcoSys_cols) + \n    scale_fill_manual(name = \"Økosystem\", values = EcoSys_cols[which(names(EcoSys_cols) %in% sub_fidData$ecosystem)]) + \n    scale_y_continuous(breaks = posData$pos, labels = paste0(sub_fidData$fidelity, \"%\")) +\n    theme(axis.ticks = element_blank(),\n          axis.title = element_blank(),\n          axis.text = element_text(size = 15), \n          panel.background = element_rect(fill = \"white\"))\n  )\n\n}"},{"path":"other-figures.html","id":"impact-factor-wordclouds","chapter":"5 Other figures","heading":"5.3 Impact factor wordclouds","text":"per now, website shows important impact factors indicator list pop-window top-right. information likely great interest general public, benefit placed visible website engaging way list. One attractive alternative way presenting via wordclouds.following wordcloud figures show pressure factors indicator, color saturation text size represent importance pressure factor. Small text size low saturation means low importance, large text size represent pressure factors high importance indicator.","code":"\n\nlibrary(wordcloud)\nlibrary(NIcalc)\nlibrary(wordcloud2)\nlibrary(RColorBrewer)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tm)\n# Load dataset\npressure = read_excel(\"P:/41201612_naturindeks_2021_2023_database_og_innsynslosning/Pilot_Forbedring_Innsynsløsning/R/Indikator_paavirkning.xlsx\")\n\n# Filter for species of interest\npressure = pressure %>% filter(navn_norsk == \"Elg\" | navn_norsk == \"Dikesoldogg\" | navn_norsk == \"Havørn\" | navn_norsk == \"Lange\" | navn_norsk == \"Jerv\" | navn_norsk == \"Lomvi\") # NB - Jerv was not included in the provided excel file\npressure = arrange(pressure, by = navn_norsk)\npressure = pressure %>% rename(PressureFactor = Paavirkningsfaktor, PressureValue = FK_PaavirkningsverdiID)\n\n# Remove all instances of \"Ikke rel/ukjent\" category\" and increase the value of pressure factors for better contrast in wordcloud figures\npressure = pressure %>% filter(PressureValue != 7) %>% mutate(PressureValue = PressureValue*2) \n\n# Create separate datasets for the different species\ndikesoldogg = pressure %>% filter(navn_norsk == \"Dikesoldogg\") %>% dplyr::select(PressureFactor, PressureValue)\n\nelg = pressure %>% filter(navn_norsk == \"Elg\") %>% dplyr::select(PressureFactor, PressureValue)\n\nhavørn = pressure %>% filter(navn_norsk == \"Havørn\") %>% dplyr::select(PressureFactor, PressureValue)\n\nlange = pressure %>% filter(navn_norsk == \"Lange\") %>% dplyr::select(PressureFactor, PressureValue)\n\nlomvi = pressure %>% filter(navn_norsk == \"Lomvi\") %>% dplyr::select(PressureFactor, PressureValue)\n\n# Create a custom color gradient (green in this case)\npressureColors = c(\"#bde4aa\", \"#addb9d\", \"#9cd28f\", \"#8cc982\", \"#7dc275\", \"#6cb967\", \"#5db15a\", \"#50a54e\", \"#479845\", \"#3f8c3b\", \"#367e31\", \"#2e7228\", \"#25661f\") "},{"path":"other-figures.html","id":"dikesoldogg-oblong-leaved-sundew","chapter":"5 Other figures","heading":"5.3.1 Dikesoldogg (oblong-leaved sundew)","text":"","code":"\n\n# Dikesoldogg\nwordcloud(words = dikesoldogg$PressureFactor, freq = dikesoldogg$PressureValue, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = pressureColors, scale = c(1.5, 0.5)) # use rot.per to set the percentage of words that are at a 90 degree angle"},{"path":"other-figures.html","id":"elg-moose","chapter":"5 Other figures","heading":"5.3.2 Elg (Moose)","text":"","code":"\n\nwordcloud(words = elg$PressureFactor, freq = elg$PressureValue, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = pressureColors, scale = c(1.5, 0.5))"},{"path":"other-figures.html","id":"havørn-white-tailed-eagle","chapter":"5 Other figures","heading":"5.3.3 Havørn (White-tailed eagle)","text":"","code":"\nwordcloud(words = havørn$PressureFactor, freq = havørn$PressureValue, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = pressureColors, scale = c(1.5, 0.5))"},{"path":"other-figures.html","id":"lange-common-ling","chapter":"5 Other figures","heading":"5.3.4 Lange (Common ling)","text":"","code":"\n\nwordcloud(words = lange$PressureFactor, freq = lange$PressureValue, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = pressureColors, scale = c(1.5, 0.5))"},{"path":"other-figures.html","id":"lomvi-common-guillemot","chapter":"5 Other figures","heading":"5.3.5 Lomvi (common guillemot)","text":"","code":"\n\nwordcloud(words = lomvi$PressureFactor, freq = lomvi$PressureValue, min.freq = 1, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = pressureColors, scale = c(1.5, 0.5))"},{"path":"other-figures.html","id":"data-type","chapter":"5 Other figures","heading":"5.4 Data type","text":"","code":"\nsource(\"R/colorPalettes.R\")\n#Elg datatyper\ndata <- data.frame(\n  category=c(\"Ekspert\", \n             \"Modeller\", \n             \"Overvåkning\"),\n  count=c(4.9, 95.1, 0)\n)\n\n# load library\nlibrary(tidyverse)\n# Compute percentages\ndata$fraction <- data$count / sum(data$count)\n\n# Compute the cumulative percentages (top of each rectangle)\ndata$ymax <- cumsum(data$fraction)\n\n# Compute the bottom of each rectangle\ndata$ymin <- c(0, head(data$ymax, n=-1))\n\n# Compute label position\ndata$labelPosition <- (data$ymax + data$ymin) / 2\ndata$labelPosition[3]<-0.8\n# Compute a good label\ndata$label <- paste0(data$category, \"\\n \", data$count, \" %\")\nlibrary(ggrepel)\n#> Warning: package 'ggrepel' was built under R version 4.1.3\n# Make the plot\nggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +\n  geom_rect() +\n  geom_text(x=2, aes(y=labelPosition, label=label, color=category), size=2.5) + # x here controls label position (inner / outer)\n  scale_fill_NIviz_d(\"IndMap_cols\") +\n  scale_colour_NIviz_d(\"IndMap_cols\") +\n  coord_polar(theta=\"y\") +\n  xlim(c(-1, 4)) +\n  theme_void() +\n  theme(legend.position = \"none\")"}]
